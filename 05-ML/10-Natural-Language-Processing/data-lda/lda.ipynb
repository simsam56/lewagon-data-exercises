{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to find topics within a corpus of emails with the **LDA** algorithm (Unsupervised Learning in NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úâÔ∏è Here is a collection of 1K+ ***unlabelled emails***. Let's try to ***extract topics*** from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T14:33:45.582330Z",
     "iopub.status.busy": "2025-11-11T14:33:45.578917Z",
     "iopub.status.idle": "2025-11-11T14:34:02.001428Z",
     "shell.execute_reply": "2025-11-11T14:34:02.001026Z",
     "shell.execute_reply.started": "2025-11-11T14:33:45.582065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/lda_data'\n",
    "\n",
    "data = pd.read_csv(url, sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T14:34:09.900446Z",
     "iopub.status.busy": "2025-11-11T14:34:09.900049Z",
     "iopub.status.idle": "2025-11-11T14:34:09.906445Z",
     "shell.execute_reply": "2025-11-11T14:34:09.905842Z",
     "shell.execute_reply.started": "2025-11-11T14:34:09.900420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning**) ‚ùì You're used to it by now... Clean up! Store the cleaned text in a new column \"clean_text\" of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T14:35:22.700503Z",
     "iopub.status.busy": "2025-11-11T14:35:22.697018Z",
     "iopub.status.idle": "2025-11-11T14:35:23.533999Z",
     "shell.execute_reply": "2025-11-11T14:35:23.533751Z",
     "shell.execute_reply.started": "2025-11-11T14:35:22.700136Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>from gld cunixb cc columbia edu gary l dare su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from atterlep vela acs oakland edu cardinal xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>from miner kuhub cc ukans edu subject re ancie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from atterlep vela acs oakland edu cardinal xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>from vzhivov superior carleton ca vladimir zhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  from gld cunixb cc columbia edu gary l dare su...  \n",
       "1  from atterlep vela acs oakland edu cardinal xi...  \n",
       "2  from miner kuhub cc ukans edu subject re ancie...  \n",
       "3  from atterlep vela acs oakland edu cardinal xi...  \n",
       "4  from vzhivov superior carleton ca vladimir zhi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Nettoyage basique : suppression des caract√®res sp√©ciaux, chiffres, liens, ponctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # liens\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)       # garde uniquement les lettres\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    # supprime espaces multiples\n",
    "    return text\n",
    "\n",
    "# Application √† la colonne \"text\"\n",
    "data[\"clean_text\"] = data[\"text\"].apply(clean_text)\n",
    "\n",
    "# V√©rifions le r√©sultat\n",
    "data[[\"text\", \"clean_text\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Train a LDA model to extract potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:37:36.286826Z",
     "iopub.status.busy": "2025-11-11T15:37:36.281605Z",
     "iopub.status.idle": "2025-11-11T15:37:39.100022Z",
     "shell.execute_reply": "2025-11-11T15:37:39.099705Z",
     "shell.execute_reply.started": "2025-11-11T15:37:36.286786Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le entra√Æn√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Vectorisation (sac de mots)\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=0.90,     # ignore mots trop fr√©quents\n",
    "    min_df=2,        # ignore mots rares\n",
    "    stop_words='english'\n",
    ")\n",
    "X = vectorizer.fit_transform(data[\"clean_text\"])\n",
    "\n",
    "# Entra√Ænement du mod√®le LDA\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=5,   # nombre de topics √† d√©couvrir\n",
    "    random_state=42,\n",
    "    learning_method='batch'\n",
    ")\n",
    "lda.fit(X)\n",
    "\n",
    "print(\"Mod√®le entra√Æn√© avec succ√®s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded for you a  function that prints the words associated with the potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:41:17.880029Z",
     "iopub.status.busy": "2025-11-11T15:41:17.878080Z",
     "iopub.status.idle": "2025-11-11T15:41:17.896441Z",
     "shell.execute_reply": "2025-11-11T15:41:17.890965Z",
     "shell.execute_reply.started": "2025-11-11T15:41:17.879953Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Print the topics extracted by your LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:42:54.129859Z",
     "iopub.status.busy": "2025-11-11T15:42:54.129126Z",
     "iopub.status.idle": "2025-11-11T15:42:54.308478Z",
     "shell.execute_reply": "2025-11-11T15:42:54.308009Z",
     "shell.execute_reply.started": "2025-11-11T15:42:54.129830Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('edu', 282.6097838797633), ('god', 278.53439356386014), ('does', 161.72631020874041), ('article', 157.43527607097502), ('question', 151.0719777020838), ('com', 137.36120896462273), ('writes', 136.09820770223698), ('ca', 100.67314867312408), ('existence', 99.48679479808875), ('reason', 96.89908570885126)]\n",
      "Topic 1:\n",
      "[('edu', 731.3257306832522), ('hockey', 603.4401904005871), ('team', 562.8976382506897), ('game', 495.0184862232725), ('ca', 357.5390806241832), ('season', 357.200425951211), ('games', 301.5573107063094), ('university', 275.3695619923858), ('nhl', 272.79302250403424), ('year', 271.99932568256577)]\n",
      "Topic 2:\n",
      "[('edu', 258.70913166245043), ('ca', 250.638530598734), ('vs', 221.64272138264133), ('pts', 217.51792115363264), ('period', 211.84022464482373), ('play', 210.69744595936652), ('la', 205.08528951025323), ('nhl', 146.60477965629113), ('pittsburgh', 145.70270523554797), ('team', 145.49987598026283)]\n",
      "Topic 3:\n",
      "[('god', 957.8718140048742), ('edu', 534.5490171403095), ('people', 460.27490219510236), ('jesus', 438.7621879773871), ('think', 332.06136217957743), ('church', 330.2978594672393), ('christian', 326.0907987583171), ('don', 294.37762412892135), ('know', 278.00686204481383), ('hell', 274.0255387917849)]\n",
      "Topic 4:\n",
      "[('edu', 320.8063366341815), ('god', 264.1924374415159), ('jesus', 187.4761067109749), ('truth', 182.27430632563753), ('people', 144.57718317286816), ('christians', 135.17266003885533), ('think', 129.28816687572473), ('know', 124.66495852324725), ('bible', 122.12707486233117), ('believe', 118.92143246934171)]\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda, vectorizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:44:49.616273Z",
     "iopub.status.busy": "2025-11-11T15:44:49.614429Z",
     "iopub.status.idle": "2025-11-11T15:44:49.647219Z",
     "shell.execute_reply": "2025-11-11T15:44:49.645984Z",
     "shell.execute_reply.started": "2025-11-11T15:44:49.616237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: edu, god, does, article, question, com, writes, ca, existence, reason\n",
      "Topic 1: edu, hockey, team, game, ca, season, games, university, nhl, year\n",
      "Topic 2: edu, ca, vs, pts, period, play, la, nhl, pittsburgh, team\n",
      "Topic 3: god, edu, people, jesus, think, church, christian, don, know, hell\n",
      "Topic 4: edu, god, jesus, truth, people, christians, think, know, bible, believe\n"
     ]
    }
   ],
   "source": [
    "def print_topics_clean(model, vectorizer, n_top_words=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        print(f\"Topic {idx}: {', '.join(top_words)}\")\n",
    "\n",
    "print_topics_clean(lda, vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Predict the document-topic mixture of a new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Prediction)** ‚ùì\n",
    "\n",
    "Now that your LDA model is fitted, you can use it to predict the topics of a new text.\n",
    "\n",
    "1. Vectorize the example\n",
    "2. Use the LDA on the vectorized example to predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:46:40.057741Z",
     "iopub.status.busy": "2025-11-11T15:46:40.054278Z",
     "iopub.status.idle": "2025-11-11T15:46:40.109710Z",
     "shell.execute_reply": "2025-11-11T15:46:40.108943Z",
     "shell.execute_reply.started": "2025-11-11T15:46:40.057594Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des topics : [[0.0200584  0.91958657 0.02019871 0.02011948 0.02003684]]\n",
      "Topic dominant : 1\n"
     ]
    }
   ],
   "source": [
    "# Exemple de texte\n",
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]\n",
    "\n",
    "# 1. Nettoyage du texte (m√™me fonction que plus haut)\n",
    "example_clean = [clean_text(example[0])]\n",
    "\n",
    "# 2. Vectorisation (avec le vectorizer d√©j√† entra√Æn√©)\n",
    "example_vec = vectorizer.transform(example_clean)\n",
    "\n",
    "# 3. Pr√©diction du m√©lange de topics\n",
    "topic_distribution = lda.transform(example_vec)\n",
    "\n",
    "# 4. Affichage du r√©sultat\n",
    "print(\"Distribution des topics :\", topic_distribution)\n",
    "print(\"Topic dominant :\", topic_distribution.argmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:59:36.603288Z",
     "iopub.status.busy": "2025-11-11T15:59:36.600753Z",
     "iopub.status.idle": "2025-11-11T15:59:49.710840Z",
     "shell.execute_reply": "2025-11-11T15:59:49.710536Z",
     "shell.execute_reply.started": "2025-11-11T15:59:36.603203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3083.975739492571\n",
      "3 3022.4119299032996\n",
      "4 2941.776849982074\n",
      "6 2926.5842600733204\n"
     ]
    }
   ],
   "source": [
    "for k in [2, 3, 4, 6]:\n",
    "    lda = LatentDirichletAllocation(n_components=k, random_state=42)\n",
    "    lda.fit(X)\n",
    "    print(k, lda.perplexity(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to implement an LDA quickly.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
